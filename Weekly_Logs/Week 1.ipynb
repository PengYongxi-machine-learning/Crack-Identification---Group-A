{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "853dc366",
   "metadata": {},
   "source": [
    "# Week 1 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877059e6",
   "metadata": {},
   "source": [
    "Inital thought is to have two different approaches:\n",
    "\n",
    "1. Training on entire dataset (cracked + uncracked)\n",
    "2. Overfitting on one of them and flagging abrupt response when unseen data is provided \n",
    "\n",
    "Now we focus on EDA which is going to be common for both. First we focus on the basic high level counts of:\n",
    "1. Decks \n",
    "    - Cracked\n",
    "    - Uncracked\n",
    "2. Walls\n",
    "    - Cracked \n",
    "    - Uncracked\n",
    "For each image we extract the RGB data and generate summary statistics then we can plot RGB frequency curves, box/violin plots to determine spread and location of each channel. This can also tell us whether there is a clear difference between wall and deck distributions, if we can compress images to grayscale, if we want to amplify certain channels to generate constrast and redistribute the channels.\n",
    "\n",
    "Plotting a curve of R, B, G values on every cracked image to see if there is any corelation of values of R, B, G with cracks in the image which could be used to classify the image as cracked and uncracked.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
